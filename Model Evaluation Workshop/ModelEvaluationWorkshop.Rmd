---
title: "Model Evaluation Workshop"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

In this exercise, we will practise model evaluation metrics in R. We will use *BreastCancer* dataset from `mlbench` package. Our aim is to classify  malignant breast cancer patients successfully. The early diagnosis of breast cancer can improve the chance of survival significantly. Therefore, correct classification of patients with malignant breast tumors is an important criterion. For more information about the data file, you can check this [link](http://ugrad.stat.ubc.ca/R/library/mlbench/html/BreastCancer.html). 

Let's first load some of the required packages and import our dataset. View the first six rows of *BreastCancer* dataset. The column "Class" shows whether a patient has cancer (malignant) or not (benign). 

```{r  message=FALSE}

library("tidyverse")

# We will use BreastCancer dataset from mlbench package
library("mlbench")

# Load BreastCancer dataset 
data(BreastCancer)

# Assign BreastCancer to BC
BC <- BreastCancer

# View the first 6 rows
head(BC)

```

### Task 1: Data Preparation

Let's first explore and prepare our data.

* Check the structure of our dataset and set the correct measurement levels for the features if necessary.

* Check the summary of our dataset. 

```{r  message=FALSE}

# Check the structure of the dataset
str(BC)

# Check the summary of the dataset
summary(BC)

```

* Remove patient "Id" column. It does not affect the target variable.

* Some models cannot handle missing values. Therefore, remove rows with missing values using `na.omit()` function.

* Check the levels of the target variable. Reorder the levels if necessary. 

```{r  message=FALSE}

# Remove patient Id column
BC$Id <- NULL

  
# Remove the missing values
BC <- na.omit(BC)
  
  
# Check the levels of the target variable. Reorder if necessary
levels(BC$Class)

```


We will build three models (Random Forest, Conditional Inference Tree and SVM) and compare their performances. First, we need to generate training and test sets. These sets will be used for all models.

* Partition the dataset into training (60%) and test (40%) sets. Do not forget to set the seed for random variables. Load `caTools` package for data partitioning.  

```{r  message=FALSE, eval = FALSE}

# Load caTools package
library(caTools)

# Set seed to 7
set.seed(7)

# Partition the data
split = sample.split(BC$Class, SplitRatio = 0.6) 

# Generate training and test sets and save as trainingset and testset
trainingset = subset(BC, split == TRUE) 

testset = subset(BC, split == FALSE) 

```

***

### Task 2: Modelling

**Random Forest**

Random Forest consists of a large number of individual decision trees that operate as a group. It is a popular ensemble method that can be used to build predictive models for both classification and regression problems. 

In order to build this model, we should load `randomForest` package.

```{r  message=FALSE, eval = FALSE}

# Install and Load randomForest package
install.packages("randomForest"")

library("randomForest")

```

Our target variable is stored in column "Class". We will use all features in our model. The basic syntax of Random Forest is given as follows:

     randomForest(formula, data)

- Formula shows which features are used in modelling to predict the target variable.

- Data is the dataset that will be used for model building.

* Build and print our Random Forest model.

* Print the importance weights of attributes by using `importance(modelname)` function from this package.

```{r  message=FALSE, eval = FALSE}

# Build Random Forest model and assign it to model_RF
model_RF <- randomForest(Class~., data = trainingset)

# Print our model
print(model_RF)

# Check the important attributes by using importance() function
importance(model_RF)

```

* Predict the classes for the test data and store the result as *prediction_RF*.

```{r  message=FALSE, eval = FALSE}

# Predict the classes for the test data
prediction_RF <- predict(model_RF, testset)

```

* Use `confusionMatrix()` function in `caret` package to print the performance metrics.

Let's load `caret` package and use `confusionMatrix()` function with three arguments; predicted target variable, actual target variable and the positive class. In order to set the positive class, we should add `positive='malignant'` argument to this function.

```{r  message=FALSE, eval = FALSE}

# Load Caret package for Confusion matrix
library(caret) 

# The last argument sets the positive class
confusionMatrix(prediction_RF, testset$Class, positive='malignant')

```

***

**Conditional Inference Tree - Ctree**

Now, we will build a conditional inference tree by using `ctree()` function. 
      
Let's load `partykit` package and build a decision tree model by using all features. Call this model *model_Ctree*. 

```{r  message=FALSE, eval = FALSE}

# Load package partykit
library(---)

# Build a decision tree by using ctree() function
model_Ctree <- ctree(--- , data = ---)


```

* Predict the classes in the test data and store the result as *prediction_CTree*. In order to return class predictions, we should set argument `type="response"` in `predict()` function.

```{r  message=FALSE, eval = FALSE}

# Predict the Test set results 
 prediction_Ctree <- predict(---, ---, type="---")

```

* Use `confusionMatrix()` function to print model performance results.

```{r  message=FALSE, eval = FALSE}

# Use confusionMatrix to print the performance of Ctree model
confusionMatrix(---, ---, positive='---')

```

***


**SVM**

Now, we will work on an SVM model. Load `e1071` package to build an SVM model. 

* Follow the same steps as in the previous models and build our SVM model. Set kernel method as linear. 

```{r  message=FALSE, eval = FALSE}

# Load e1071 package for svm
library(---)

# Build SVM model and assign it to model_SVM
model_SVM <- svm(--- , data = ---, kernel= "---", probability = TRUE)

# Print our model
print(---)

```

Note that the probability argument in `svm()` and `predict()` functions returns the vector of probabilities of belonging to each class of the target variable. 

* Predict the classes for the test data and store the result as *prediction_SVM*.

```{r  message=FALSE, eval = FALSE}

# Predict the classes for the test data
prediction_SVM <- predict(---, ---, ---)

```

* Use `confusionMatrix()` function to print model performance results.

```{r  message=FALSE, eval = FALSE}

# Use confusionMatrix to print the performance of SVM model
confusionMatrix(---, ---, positive='---')

```

***

### Task 3: Evaluation

In this task, we will visualise the performances of Random Forest, Ctree and SVM models by using ROC and Gain charts. To plot these charts, we should load `pROC` package. We use `roc()` function to evaluate the results of the predictive models. 

* Obtain class probabilities (likelihood of belonging to a class) for Random Forest, Ctree and SVM models built in task 2.

In order to obtain class probabilities for Random Forest and Ctree, we will use `predict()` function with an additional argument `type="prob"`.

```{r  message=FALSE, eval = FALSE}

# Load the ROCR package
library(---) 

# Obtain class probabilities by using predict() function with type = "prob" for Random Forest
prob_RF <- predict(---, ---, type = "---")

# Obtain class probabilities by using predict() function with type = "prob" for Ctree
prob_Ctree <- predict(---, ---, type = "---")

# Obtain class probabilities for SVM
prob_SVM <- attr(---, "---")[,2]


```

* Use `roc()` function to generate input data for ROC curve.

Random Forest:
```{r  message=FALSE, eval = FALSE}

# Random Forest
# Use roc function to return some performance metrics
ROC_RF <- roc(--- ~ prob_RF[,2], data = ---)

# Extract required data from ROC_RF
df_RF = data.frame(---, ---)

```

Ctree:
```{r  message=FALSE, eval = FALSE}

# Conditional Inference Tree - CTree
# Use roc function to return some performance metrics
ROC_Ctree <- roc(--- ~ prob_Ctree[,2], ---)

# Extract required data from ROC_Ctree
df_Ctree = data.frame(---, ---)

```


SVM:
```{r  message=FALSE, eval = FALSE}

# SVM
# Use roc function to return some performance metrics
ROC_SVM <- roc(--- ~ ---, data = ---)

#Extract required data from ROC_SVM
df_SVM = data.frame(---, ---)

```

* Plot ROC charts for Random Forest, Ctree and SVM models. 

```{r  message=FALSE, eval = FALSE}

#plot the ROC curve for Random Forest, Ctree and SVM

plot(---, col="red", type="l",          #adds ROC curve for Random Forest
xlab="False Positive Rate (1-Specificity)", ylab="True Positive Rate (Sensitivity)")
lines(---, col="green")                 #adds ROC curve for Ctree
lines(---, col="blue")                  #adds ROC curve for SVM
abline(a = 0, b = 1, col = "lightgray") #adds a diagonal line

legend("bottomright",
c("Random Forest","Ctree", "SVM"),
fill=c("red","green", "blue"))

```

* Compute AUC values for Random Forest, Ctree and SVM models by using `auc()` function. You can use “roc” object obtained from `roc()` function to compute AUC value.

```{r  message=FALSE, eval = FALSE}

# Calculate the area under the curve (AUC) for Random Forest and print it
AUC_RF <- auc(---)

# Print AUC for Random Forest
print(---)

# Calculate the area under the curve (AUC) for Ctree and print it
AUC_Ctree <- auc(---)

# Print AUC for Ctree
print(---)

# Calculate the area under the curve (AUC) for SVM and print it
AUC_SVM <- auc(---)

# Print AUC for SVM
print(---)

```

***

Next, we will plot Cumulative Response (Gain) chart for Random Forest, Ctree and SVM models developed in task 2. For this task, we need to install and load `CustomerScoringMetrics` package. Specifically, we will use `cumGainsTable()` function to calculate cumulative gain values for our chart. This function takes three arguments. The first one is the prediction probabilities (scores), the second one is the actual values of the target variables and the third one is the increment of the threshold value.


```{r  message=FALSE}

# Install and load the CustomerScoringMetrics package
#Install.packages("CustomerScoringMetrics")
library(CustomerScoringMetrics)

```

* Compute gain chart values for Random Forest, Ctree and SVM.

```{r  message=FALSE, eval = FALSE}

# Obtain Gain chart values for Random Forest for the target value malignant 
GainTable_RF <- cumGainsTable(---, ---, resolution = 1/100)

# Obtain Gain chart values for Ctree for the target value malignant 
GainTable_Ctree <- cumGainsTable(---, ---, resolution = 1/100)

# Obtain Gain chart values for SVM for the target value malignant 
GainTable_SVM <- cumGainsTable(---, ---, resolution = 1/100)

```

* Plot the gain chart for Random Forest, Ctree and SVM.

```{r  message=FALSE, eval = FALSE}

plot(---, col="red", type="l",        # plots gain chart for Random Forest 
xlab="Percentage of test instances", ylab="Percentage of correct predictions")
lines(---, col="green", type="l")     # plots gain chart for Ctree
lines(---, col="blue", type="l")      # plots gain chart for SVM
abline(a = 0, b = 1, col = "lightgray") #adds a diagonal line

legend("bottomright",
c("Random Forest","Ctree", "SVM"),
fill=c("red","green", "blue"))

```

