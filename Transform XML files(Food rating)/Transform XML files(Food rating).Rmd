---
title: "Transform XML files(Food rating)"
author: "Ingeon Hwang"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We aim to fetch the rating dataset from the government website and store it available for further analysis. 

### Transform XML files(Food rating)


First of all, we load some of the required packages 
```{r, eval=FALSE}
# install.packages('rvest')
rm(list = ls())
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(tidyverse)
library(xml2)
library(XML)
library(naniar)
```


```{r, eval=FALSE}
# Instead of converting the factors to 
# characters on the data frame construction 
# we can use this by default
options(stringsAsFactors = FALSE)
```

Setting the url source content 
```{r, eval=FALSE}
ratings_file_list <- 'https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200'
```
 
Calling the page by using read_html( )
```{r, eval=FALSE}
# Fetch the source content 
ratings_file_list <- 'https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200'
source_ratings <- read_html(ratings_file_list)

# Use rvest to extract the href attribute of the links
source_ratings_urls  <- source_ratings %>% 
  html_nodes(".o-dataset-distribution--link") %>% 
  html_attr("href")

# Do the same for the titles from the h4 element
# Extract the 'title' attribute from the url 
source_rating_titles <- source_ratings %>% 
  html_nodes(".c-dataset-element--title") %>% 
  html_text() %>%
  trimws(.) 
  
```


Construct a data frame of two columns, one for the rating titles and one for the urls
```{r, eval=FALSE}
my_data_frame <- data.frame(
  title = source_rating_titles,
  urls = source_ratings_urls 
)

```

Remove the first file from the list of XML that we do not need 
```{r, eval=FALSE}
my_data_frame <- my_data_frame[-1,]
```

Use a loop to download the file. First for loop is for calling every URL address. Second for loop is for downloading whole XML files by using the URL address and then designate the style of the file name which we download.
```{r, eval=FALSE}
for (url_index in 1:nrow(my_data_frame)) {
  # extract the last element of the list 
  # note that the [[1]] is there because the 
  # argument we supplied to strsplit is a vector 
  # of size 1 
    split_elements <- strsplit(my_data_frame$urls[url_index],split = "/"    )[[1]]
    # So we want to get the last element 
    # and in a vector the position of the last element 
    # is equal to the length of the vector
    my_file_name <- split_elements[length(split_elements)]
    #download the files
    download.file(url = my_data_frame$urls[url_index], 
                destfile = paste0("xml_files", my_file_name))}

```

If you have a specific folder contains the files which downloaded from previous step, you can assign the folder name for make a path. (Validating the list of XML files downloaded in the xml_dest folder)
```{r, eval=FALSE}
datafolder <- "xml_dest/"  # write down the folder name which contains the files in the ""
filesinfolder <- list.files(datafolder)
this_folder_path <- paste(datafolder, filesinfolder,sep="")

for(f in list.files("xml_files")){
  print(f)
}
# view(this_folder_path)
```  

Remove data stored in Welsh language
```{r, eval=FALSE}
this_folder_path_EN <- this_folder_path[!grepl("cy", this_folder_path)]

```  


The following code is meant to transform the XML files into a data frame that captured required defined fields. We use a first for loop to execute every xml files which we saved it in 'this_folder_path_EN' and
use a second for loop to call the every data in 'this_establishment_collections[[k]]'. We made a local data frame to save the whole columns and rows which we got by using 'unlist' function. After that transposes the rows and columns of matrices by using 't()'. Data in the data frame is stored in the 'city_data' by using bind_rows. We clean the data frame after abstract the data by making an empty data frame. 
```{r, eval=FALSE}
city_data <- data.frame()
whole_data_frame <- data.frame()

 for(i in 1:length(this_folder_path_EN)){ 
   
    data <- XML::xmlToList(this_folder_path_EN[i])
    this_establishment_collections <- data$EstablishmentCollection  
   
  for(k in 1:length(this_establishment_collections)) {
    new_list <- unlist(this_establishment_collections[[k]])
    
    tlist <- t(new_list)  # Transpose to matrice
    
    dataframe <- as.data.frame(tlist, stringsAsFactors = FALSE) # Change to dataframe
    city_data <- bind_rows(city_data,dataframe )
    dataframe <- data.frame()     # Clean the data frame after abstract the data
  }
    whole_data_frame <- bind_rows(whole_data_frame, city_data)
    city_data <- data.frame()  # Clean the data frame after abstract the data 
 }    
    
# Save the whole_data_frame to CSV file ('PartC_result.csv')
write.table(whole_data_frame, file = "PartC_result.csv", sep=",", row.names = FALSE) 

```
